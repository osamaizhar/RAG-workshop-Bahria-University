{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file now only contains the upsert and updating Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All imports and inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "import gradio as gr\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Important: Import pinecone-client properly\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "PINECONE_API = os.getenv(\"PINECONE_API\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_CHAT_URL = os.getenv(\"GROQ_CHAT_URL\")\n",
    "\n",
    "# Configure headers for Groq API requests\n",
    "GROQ_HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Input:\n",
    "    - Context window: 128K\n",
    "Ouput:\n",
    "    - Output Max Tokens: 32,768\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# LLM_MODEL = \"llama3-70b-8192\"\n",
    "LLM_MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "\n",
    "def track_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f\"[Time Tracker] `{func.__name__}` took {end - start:.4f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@track_time\n",
    "def pdf_load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Directory Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_documents():\n",
    "#     \"\"\"\n",
    "#     Load PDF and Excel files from DATA_PATH.\n",
    "#     Returns a list of documents with content and metadata and a list of filenames.\n",
    "#     \"\"\"\n",
    "#     documents = []\n",
    "#     file_names = []\n",
    "\n",
    "#     # Load PDFs\n",
    "#     pdf_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "#     pdf_docs = pdf_loader.load()\n",
    "#     for doc in pdf_docs:\n",
    "#         documents.append({\n",
    "#             \"content\": doc.page_content,\n",
    "#             \"metadata\": {\"source\": doc.metadata.get(\"source\", \"unknown\"), \"file_type\": \"pdf\"}\n",
    "#         })\n",
    "#         file_names.append(doc.metadata.get(\"source\", \"unknown\"))\n",
    "\n",
    "#     # Load Excel files\n",
    "#     excel_files = glob.glob(os.path.join(DATA_PATH, \"*.xlsx\"))\n",
    "#     for file in excel_files:\n",
    "#         df = pd.read_excel(file)\n",
    "#         headers = df.columns.tolist()\n",
    "#         for _, row in df.iterrows():\n",
    "#             content = \" \".join([f\"{col}: {str(row[col])}\" for col in headers])\n",
    "#             documents.append({\n",
    "#                 \"content\": content,\n",
    "#                 \"metadata\": {\"source\": file, \"file_type\": \"excel\"}\n",
    "#             })\n",
    "#         file_names.append(file)\n",
    "\n",
    "#     if not documents:\n",
    "#         print(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "#     else:\n",
    "#         print(f\"Loaded {len(documents)} documents\")\n",
    "\n",
    "#     return documents, file_names\n",
    "\n",
    "\n",
    "# # Load documents\n",
    "# documents, file_names = load_documents()\n",
    "\n",
    "# # Print file names\n",
    "# print(\"Files parsed:\")\n",
    "# for name in file_names:\n",
    "#     print(f\"- {name}\")\n",
    "\n",
    "# print(f\"\\nTotal documents loaded: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Directory Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF DOCS len: \n",
      "\n",
      " 72\n",
      "Parsed Excel file: D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Exam 01.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 01 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 02 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 03 - Quiz.xlsx\n",
      "Parsed Excel file: D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 04 - Quiz.xlsx\n",
      "Loaded 85 documents\n",
      "Files parsed:\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\10--Decoding-Communication-22042025-022943pm.pdf\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\11--Styles-of-Critical-Thinkers-and-Non-Critical-Thinkers-22042025-023718pm.pdf\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\12---DLL-MAC2-15052025-013017pm.pdf\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\12--Step-by-step-analysis-of-argument-24042025-105459am.pdf\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\13---Ntw-15052025-013046pm.pdf\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Exam 01.xlsx\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 01 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 02 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 03 - Quiz.xlsx\n",
      "- D:\\Disrupt Labs\\RAG-workshop-Bahria-University\\data\\Lesson 04 - Quiz.xlsx\n",
      "[Time Tracker] `load_documents` took 0.8063 seconds\n",
      "\n",
      "Total documents loaded: 85\n"
     ]
    }
   ],
   "source": [
    "@track_time\n",
    "def load_documents():\n",
    "    \"\"\"\n",
    "    Load PDF and Excel files from DATA_PATH and its subdirectories.\n",
    "    Returns a list of documents with content and metadata, and a list of filenames.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    file_names = []\n",
    "    processed_files = []\n",
    "\n",
    "    # Load PDFs from all subdirectories\n",
    "    pdf_loader = PyPDFDirectoryLoader(DATA_PATH, recursive=True)\n",
    "    pdf_docs = pdf_loader.load()\n",
    "    print(\"PDF DOCS len: \\n\\n\", len(pdf_docs))\n",
    "    # print(\"PDF DOCS: \\n\\n\",pdf_docs)\n",
    "    count = 0\n",
    "    for doc in pdf_docs:\n",
    "        source = doc.metadata.get(\"source\", \"unknown\")\n",
    "        if source not in processed_files:\n",
    "            documents.append({\n",
    "                \"content\": doc.page_content,\n",
    "                \"metadata\": {\"source\": source, \"file_type\": \"pdf\"}\n",
    "            })\n",
    "            # print(f\"PARSED DATA {source}: \\n\",documents[-1])\n",
    "\n",
    "            processed_files.append(source)\n",
    "            file_names.append(source)\n",
    "            # print(f\"Parsed PDF file : {source}\")\n",
    "        # print(\"COUNT: \", count)\n",
    "        count += 1\n",
    "   # return\n",
    "\n",
    "    # Load Excel files from all subdirectories\n",
    "    for root, _, files in os.walk(DATA_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                if file_path not in processed_files:\n",
    "                    df = pd.read_excel(file_path)\n",
    "                    headers = df.columns.tolist()\n",
    "                    for _, row in df.iterrows():\n",
    "                        content = \" \".join(\n",
    "                            [f\"{col}: {str(row[col])}\" for col in headers])\n",
    "                        documents.append({\n",
    "                            \"content\": content,\n",
    "                            \"metadata\": {\"source\": file_path, \"file_type\": \"excel\"}\n",
    "                        })\n",
    "                        # print(\"PARSED DATA: \\n\\n\\n\",documents[-1])\n",
    "                    processed_files.append(file_path)\n",
    "                    file_names.append(file_path)\n",
    "                    print(f\"Parsed Excel file: {file_path}\")\n",
    "\n",
    "    if not documents:\n",
    "        print(f\"No PDF or Excel files found in {DATA_PATH}\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(documents)} documents\")\n",
    "    # Print file names\n",
    "    print(\"Files parsed:\")\n",
    "    for name in processed_files:\n",
    "        print(f\"- {name}\")\n",
    "    return documents, file_names\n",
    "\n",
    "\n",
    "# Load documents\n",
    "documents, file_names = load_documents()\n",
    "\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splitting \\ Chunking using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Time Tracker] `split_documents` took 0.0025 seconds\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "@track_time\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False  # considers separators like '\\n\\n' if true\n",
    "    )\n",
    "    # Assuming each document is a dictionary with 'content' and 'metadata'\n",
    "    docs = []\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc['content'])\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            docs.append({\n",
    "                \"content\": chunk,\n",
    "                \"metadata\": {\n",
    "                    **doc['metadata'],\n",
    "                    \"chunk_id\": i\n",
    "                }\n",
    "            })\n",
    "    return docs\n",
    "\n",
    "\n",
    "# Split documents into chunks\n",
    "chunks = split_documents(documents)\n",
    "print(len(chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcsk_2XeHSs_NmHyZyVHBeEdDRpGe2G1dW2ZzoprF92KnYVwUh5oHnN7RAFPmXhqGMYMmBfo2LV\n"
     ]
    }
   ],
   "source": [
    "pc = Pinecone(api_key=PINECONE_API)\n",
    "print(PINECONE_API)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use What:\n",
    "**Use Upsert:**\n",
    "\n",
    "When you're adding new vectors or want to replace existing vectors with new data (including changing the vector values).\n",
    "When you need to add a completely new document or vector.\n",
    "When you want to update both the vector values and metadata.\n",
    "\n",
    "**Use Update:**\n",
    "\n",
    "When you're only modifying the metadata of an existing vector.\n",
    "When the vector values (embeddings) themselves are correct and only extra information like text, author, or document-related metadata needs to be updated.\n",
    "Summary:\n",
    "Upsert: Adds or replaces both the vector values and metadata. Use when inserting or completely replacing data.\n",
    "Update: Modifies the metadata without changing the vector values. Use when the vectors are correct, but metadata needs an update.\n",
    "For your case, if you just want to add or update the page_content or any other metadata for existing vectors, use update. If you want to re-upload vectors with new embeddings or metadata, use upsert.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings Via AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-en'  and Upsert each to Pinecone one by one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Time Tracker] `get_embedding` took 0.0862 seconds\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "embedding_model = AutoModel.from_pretrained(\n",
    "    'jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)\n",
    "\n",
    "# Function to generate embeddings without tokenization\n",
    "\n",
    "#@track_time\n",
    "def get_embedding(data):\n",
    "    embeddings = embedding_model.encode(data).tolist()\n",
    "    return embeddings\n",
    "print(len(get_embedding(\"Hello World!\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Time Tracker] `get_embedding` took 1.3807 seconds\n",
      "Embedding 1 upserted to Pinecone with metadata\n",
      "[Time Tracker] `get_embedding` took 0.0407 seconds\n",
      "Embedding 2 upserted to Pinecone with metadata\n",
      "[Time Tracker] `get_embedding` took 0.0300 seconds\n",
      "Embedding 3 upserted to Pinecone with metadata\n",
      "[Time Tracker] `get_embedding` took 0.0304 seconds\n",
      "Embedding 4 upserted to Pinecone with metadata\n",
      "[Time Tracker] `get_embedding` took 0.0339 seconds\n",
      "Embedding 5 upserted to Pinecone with metadata\n",
      "[Time Tracker] `get_embedding` took 0.1375 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAll \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m embeddings have been upserted to Pinecone\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Assuming `index` is your Pinecone index and `chunks` is the list of chunked documents\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[43mupsert_chunks_to_pinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# query_embeddings = embedding_model.encode(user_query).tolist()\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# query_embeddings\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mtrack_time.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     start = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     end = time.perf_counter()\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Time Tracker] `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mupsert_chunks_to_pinecone\u001b[39m\u001b[34m(index, chunks)\u001b[39m\n\u001b[32m     20\u001b[39m vector_id = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvec_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Upsert the embedding along with its metadata\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m upserted to Pinecone with metadata\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\utils\\error_handling.py:15\u001b[39m, in \u001b[36mvalidate_and_convert_errors.<locals>.inner_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner_func\u001b[39m(*args, **kwargs):\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     17\u001b[39m         \u001b[38;5;66;03m# Lazy import of urllib3 exceptions\u001b[39;00m\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaxRetryError, ProtocolError \u001b[38;5;28;01mas\u001b[39;00m Urllib3ProtocolError\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\db_data\\index.py:188\u001b[39m, in \u001b[36mIndex.upsert\u001b[39m\u001b[34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masync_req is not supported when batch_size is provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    183\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo upsert in parallel, please follow: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.pinecone.io/docs/insert-data#sending-upserts-in-parallel\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m     )\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_upsert_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m batch_size <= \u001b[32m0\u001b[39m:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mbatch_size must be a positive integer\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\db_data\\index.py:214\u001b[39m, in \u001b[36mIndex._upsert_batch\u001b[39m\u001b[34m(self, vectors, namespace, _check_type, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_upsert_batch\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     vectors: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m     **kwargs,\n\u001b[32m    213\u001b[39m ) -> UpsertResponse:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vector_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_vectors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIndexRequestFactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_openapi_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:102\u001b[39m, in \u001b[36mEndpoint.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m     94\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\core\\openapi\\db_data\\api\\vector_operations_api.py:675\u001b[39m, in \u001b[36mVectorOperationsApi.__init__.<locals>.__upsert_vectors\u001b[39m\u001b[34m(self, upsert_request, **kwargs)\u001b[39m\n\u001b[32m    673\u001b[39m kwargs = \u001b[38;5;28mself\u001b[39m._process_openapi_kwargs(kwargs)\n\u001b[32m    674\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mupsert_request\u001b[39m\u001b[33m\"\u001b[39m] = upsert_request\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:134\u001b[39m, in \u001b[36mEndpoint.call_with_http_info\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m params = EndpointUtils.gather_params(\n\u001b[32m    125\u001b[39m     attribute_map=\u001b[38;5;28mself\u001b[39m.attribute_map,\n\u001b[32m    126\u001b[39m     location_map=\u001b[38;5;28mself\u001b[39m.location_map,\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m     kwargs=kwargs,\n\u001b[32m    130\u001b[39m )\n\u001b[32m    132\u001b[39m HeaderUtil.prepare_headers(headers_map=\u001b[38;5;28mself\u001b[39m.headers_map, params=params)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mendpoint_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp_method\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbody\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43masync_req\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_threadpool_executor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43masync_threadpool_executor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_check_return_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_return_http_data_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_preload_content\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_request_timeout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcollection_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:306\u001b[39m, in \u001b[36mApiClient.call_api\u001b[39m\u001b[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.threadpool_executor.submit(\n\u001b[32m    286\u001b[39m         \u001b[38;5;28mself\u001b[39m.__call_api,\n\u001b[32m    287\u001b[39m         resource_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m         _check_type,\n\u001b[32m    303\u001b[39m     )\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pool.apply_async(\n\u001b[32m    326\u001b[39m     \u001b[38;5;28mself\u001b[39m.__call_api,\n\u001b[32m    327\u001b[39m     (\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m     ),\n\u001b[32m    345\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:170\u001b[39m, in \u001b[36mApiClient.__call_api\u001b[39m\u001b[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[39m\n\u001b[32m    161\u001b[39m url = build_request_url(\n\u001b[32m    162\u001b[39m     config=config,\n\u001b[32m    163\u001b[39m     processed_path_params=path_params_tuple,\n\u001b[32m    164\u001b[39m     resource_path=resource_path,\n\u001b[32m    165\u001b[39m     _host=_host,\n\u001b[32m    166\u001b[39m )\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     response_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m     e.body = e.body.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:386\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[39m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rest_client.OPTIONS(\n\u001b[32m    377\u001b[39m         url,\n\u001b[32m    378\u001b[39m         query_params=query_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    383\u001b[39m         body=body,\n\u001b[32m    384\u001b[39m     )\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrest_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mPUT\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rest_client.PUT(\n\u001b[32m    397\u001b[39m         url,\n\u001b[32m    398\u001b[39m         query_params=query_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    403\u001b[39m         body=body,\n\u001b[32m    404\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:146\u001b[39m, in \u001b[36mRestClientInterface.POST\u001b[39m\u001b[34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mPOST\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    138\u001b[39m     url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    144\u001b[39m     _request_timeout=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    145\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\pinecone\\openapi_support\\rest_urllib3.py:190\u001b[39m, in \u001b[36mUrllib3RestClient.request\u001b[39m\u001b[34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[39m\n\u001b[32m    188\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# content_type == \"application/json\":\u001b[39;00m\n\u001b[32m    189\u001b[39m             request_body = json.dumps(body)\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m content_type == \u001b[33m\"\u001b[39m\u001b[33mapplication/x-www-form-urlencoded\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    200\u001b[39m     r = \u001b[38;5;28mself\u001b[39m.pool_manager.request(\n\u001b[32m    201\u001b[39m         method,\n\u001b[32m    202\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m         headers=headers,\n\u001b[32m    208\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\urllib3\\poolmanager.py:443\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    441\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Disrupt Labs\\RAG-workshop-Bahria-University\\bahria-env\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1411\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1409\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1413\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:324\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    326\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:285\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    287\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1249\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1245\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1246\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1247\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1248\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Connect to the index\n",
    "index = pc.Index(\"bahria\")\n",
    "\n",
    "\n",
    "@track_time\n",
    "def upsert_chunks_to_pinecone(index, chunks):\n",
    "    count = 1\n",
    "    for chunk in chunks:\n",
    "        # Ensure the chunk has the correct structure\n",
    "        content = chunk.get(\"content\")\n",
    "        metadata = chunk.get(\"metadata\", {})\n",
    "\n",
    "        # Get the embedding for the chunk\n",
    "        embedding = get_embedding(content)\n",
    "\n",
    "        # Add the text as part of the metadata\n",
    "        metadata[\"text\"] = content  # Store text in metadata\n",
    "\n",
    "        # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "        vector_id = f\"vec_{count}\"\n",
    "\n",
    "        # Upsert the embedding along with its metadata\n",
    "        index.upsert(vectors=[(vector_id, embedding, metadata)])\n",
    "\n",
    "        print(f\"Embedding {count} upserted to Pinecone with metadata\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"All {count - 1} embeddings have been upserted to Pinecone\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Assuming `index` is your Pinecone index and `chunks` is the list of chunked documents\n",
    "upsert_chunks_to_pinecone(index, chunks)\n",
    "\n",
    "# query_embeddings = embedding_model.encode(user_query).tolist()\n",
    "# query_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Vectors Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pinecone_chunks(index, chunks):\n",
    "    count = 1\n",
    "    for chunk in chunks:\n",
    "        # Get updated embedding\n",
    "        embedding = get_embedding(chunk.page_content)\n",
    "\n",
    "        # Extract metadata and page content\n",
    "        metadata = chunk.metadata\n",
    "        text = chunk.page_content\n",
    "\n",
    "        # Create a unique vector ID for each chunk (e.g., based on count or some unique identifier)\n",
    "        vector_id = f\"vec_{count}\"\n",
    "\n",
    "        # Update the embedding and metadata\n",
    "        index.update(id=vector_id, values=embedding, set_metadata=metadata)\n",
    "\n",
    "        print(f\"Embedding {count} updated in Pinecone with new metadata\")\n",
    "        count += 1\n",
    "\n",
    "    print(f\"All {count-1} embeddings have been updated in Pinecone\")\n",
    "\n",
    "# update_pinecone_chunks(index, chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since your application is designed to answer a wide range of student queries and suggest relevant material, you want to retrieve enough content to cover different facets of a topic without overwhelming the LLM with too much information.\n",
    "\n",
    "# Starting Point:\n",
    "- A common starting point is to set top_k between **5 and 10.**\n",
    "- **top_k=5:** This can work well if your curated content is highly relevant and precise, ensuring that the top 5 matches are very close to the query.\n",
    "-  **top_k=10:** If you want the coach to consider a broader range of contentperhaps to provide diverse perspectives or cover a topic more comprehensivelyincreasing top_k to around 10 might be beneficial.\n",
    "\n",
    "# Experiment and Adjust:\n",
    "- The best value depends on factors such as the diversity of your content, how densely your data covers the topics, and the quality of the embedding matches. Its a good idea to experiment with different top_k values and evaluate the quality and relevance of the responses in your specific\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bahria-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
